{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from pypfopt import risk_models\n",
    "from sklearn import preprocessing\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from datetime import date, datetime, timedelta\n",
    "from arch import arch_model\n",
    "from pypfopt import expected_returns\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return calculation\n",
    "def ReturnCalculation (Database,lag):\n",
    "    dimension=Database.shape[0];dif=lag;Out=np.zeros([dimension-dif])\n",
    "    for i in range(dimension-dif):\n",
    "        Out[i]=(np.log(Database['Close'][i+dif])-np.log(Database['Close'][i]))\n",
    "    return np.append(np.repeat(np.nan, dif),Out), Database.index\n",
    "\n",
    "#STD Calculation\n",
    "def SDCalculation (DailyReturns, LagSD):\n",
    "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif])\n",
    "    for i in range (dimension-dif):\n",
    "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
    "    return np.append(np.repeat(np.nan, dif),Out)\n",
    "\n",
    "#STD Calculation\n",
    "def TrueSDCalculation (DailyReturns, LagSD):\n",
    "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif+1])\n",
    "    for i in range (dimension-dif+1):\n",
    "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
    "    return np.append(Out,np.repeat(np.nan, dif-1))\n",
    "\n",
    "#Database is calculated\n",
    "def DatabaseGeneration (Database, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database,Lag)\n",
    "    DailyReturnsOld =  np.append(np.repeat(np.nan, 1),DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
    "    SD = SDCalculation (DailyReturns, LagSD)\n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
    "    Data = pd.DataFrame({'DailyReturns': DailyReturns, 'SD': SD, 'TrueSD': TrueSD, 'DailyReturnsOld': DailyReturnsOld})\n",
    "    Data = Data.set_index(Index) \n",
    "    return Data.dropna()\n",
    "\n",
    "\n",
    "#Database is calculated\n",
    "def M_DatabaseGeneration (Database_daily, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database_daily,Lag)    \n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)    \n",
    "    Data = pd.DataFrame({'DailyReturns': DailyReturns,'TrueSD': TrueSD})\n",
    "    Data = Data.set_index(Index)\n",
    "    Data = Data.dropna() \n",
    "    weekly_returns = Data['DailyReturns'].resample('W-FRI').sum()\n",
    "    weekly_average_volatility = Data['TrueSD'].resample('W-FRI').mean()*np.sqrt(5)\n",
    " \n",
    "    \n",
    "    Data = pd.DataFrame({'DailyReturns': weekly_returns,'TrueSD': weekly_average_volatility})\n",
    "    return Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyReturns</th>\n",
       "      <th>SD</th>\n",
       "      <th>TrueSD</th>\n",
       "      <th>DailyReturnsOld</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-02-15</th>\n",
       "      <td>0.013949</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.016481</td>\n",
       "      <td>-0.047047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-22</th>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.013949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>-0.016753</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-07</th>\n",
       "      <td>-0.028401</td>\n",
       "      <td>0.035199</td>\n",
       "      <td>0.029389</td>\n",
       "      <td>-0.016753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-14</th>\n",
       "      <td>-0.004052</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>-0.028401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-06</th>\n",
       "      <td>0.009496</td>\n",
       "      <td>0.011685</td>\n",
       "      <td>0.024921</td>\n",
       "      <td>0.002027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-13</th>\n",
       "      <td>-0.036955</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>0.029743</td>\n",
       "      <td>0.009496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-20</th>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.022117</td>\n",
       "      <td>0.025132</td>\n",
       "      <td>-0.036955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-27</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>0.023524</td>\n",
       "      <td>0.032165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-04</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
       "Date                                                         \n",
       "2008-02-15      0.013949  0.041708  0.016481        -0.047047\n",
       "2008-02-22      0.002308  0.043323  0.022702         0.013949\n",
       "2008-02-29     -0.016753  0.033929  0.022685         0.002308\n",
       "2008-03-07     -0.028401  0.035199  0.029389        -0.016753\n",
       "2008-03-14     -0.004052  0.024224  0.029213        -0.028401\n",
       "...                  ...       ...       ...              ...\n",
       "2015-11-06      0.009496  0.011685  0.024921         0.002027\n",
       "2015-11-13     -0.036955  0.011768  0.029743         0.009496\n",
       "2015-11-20      0.032165  0.022117  0.025132        -0.036955\n",
       "2015-11-27      0.000450  0.026294  0.023524         0.032165\n",
       "2015-12-04      0.000756  0.024922  0.023549         0.000450\n",
       "\n",
       "[408 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start = '2009-01-01';end = '2013-01-01'\n",
    "start='2008-01-01'; end='2015-12-31'; \n",
    "asset = \"^GSPC\"\n",
    "Lag=1; LagSD=5\n",
    "IndexEndDays=yf.download(asset,start=start,  end=end, progress=False).resample('W-FRI').last().index\n",
    "Database=yf.download(asset,start, end, progress=False).resample('W-FRI').last()\n",
    "\n",
    "Data = DatabaseGeneration(Database, Lag, LagSD)\n",
    "Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyReturns</th>\n",
       "      <th>TrueSD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-0.024858</td>\n",
       "      <td>0.036723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-11</th>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.034526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-18</th>\n",
       "      <td>-0.055645</td>\n",
       "      <td>0.036154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.032903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-01</th>\n",
       "      <td>0.047558</td>\n",
       "      <td>0.034690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-27</th>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.014414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-04</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.030913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-11</th>\n",
       "      <td>-0.038659</td>\n",
       "      <td>0.025918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-18</th>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.032131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-25</th>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.016452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DailyReturns    TrueSD\n",
       "Date                              \n",
       "2008-01-04     -0.024858  0.036723\n",
       "2008-01-11     -0.007545  0.034526\n",
       "2008-01-18     -0.055645  0.036154\n",
       "2008-01-25      0.004082  0.032903\n",
       "2008-02-01      0.047558  0.034690\n",
       "...                  ...       ...\n",
       "2015-11-27      0.000450  0.014414\n",
       "2015-12-04      0.000756  0.030913\n",
       "2015-12-11     -0.038659  0.025918\n",
       "2015-12-18     -0.003395  0.032131\n",
       "2015-12-25      0.028868  0.016452\n",
       "\n",
       "[417 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start = '2009-01-01';end = '2013-01-01'\n",
    "start='2008-01-01'; end='2015-12-31'; \n",
    "asset = \"^GSPC\"\n",
    "Lag=1; LagSD=5\n",
    "IndexEndDays=yf.download(asset,start=start,  end=end, progress=False).resample('W-FRI').last().index\n",
    "Database=yf.download(asset,start, end, progress=False)\n",
    "Database_daily=yf.download(asset,start, end, progress=False)\n",
    "Data = M_DatabaseGeneration(Database_daily, Lag, LagSD)\n",
    "Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.__future__ import reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting of GARCH(1,1)\n",
    "def GARCH_Model_Student (Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    GARCH11 = arch_model(AR_Data, dist ='t')\n",
    "    res_GARCH11 = GARCH11.fit(disp='off')\n",
    "    CV_GARCH11 = res_GARCH11.conditional_volatility\n",
    "    For_CV_GARCH11 = np.array(res_GARCH11.forecast(horizon=4).variance.dropna())\n",
    "    return GARCH11, res_GARCH11, CV_GARCH11, For_CV_GARCH11\n",
    "\n",
    "def TARCH_Model_Student(Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    TARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist ='t')\n",
    "    res_TARCH11 = TARCH11.fit(disp='off')\n",
    "    CV_TARCH11 = res_TARCH11.conditional_volatility\n",
    "    For_CV_TARCH11 = []\n",
    "    for i in range(4):\n",
    "        forecast = res_TARCH11.forecast(start=AR_Data.shape[0]-1, horizon=1)\n",
    "        For_CV_TARCH11.append(forecast.variance.iloc[-1,:].values[0])\n",
    "        AR_Data = np.append(AR_Data, forecast.mean.iloc[-1,:].values[0])\n",
    "        TARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist ='t')\n",
    "        res_TARCH11 = TARCH11.fit(disp='off')\n",
    "    return TARCH11, res_TARCH11, CV_TARCH11, np.array(For_CV_TARCH11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GARCH11, res_GARCH11, CV_GARCH11, For_CV_GARCH11 = TARCH_Model_Student (Data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1, modify GARCH models to be multistep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find that the TARCH model does not support a horizon greater than 1, one workaround could be to implement recursive forecasting manually. This would involve using the model to make a one-step ahead forecast, appending that forecast to your time series, and then making the next one-step ahead forecast, and so on until you have made 4 forecasts. However, this approach would also be based on the assumption that future residuals are zero, and it would be computationally more intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return calculation\n",
    "def ReturnCalculation (Database,lag):\n",
    "    dimension=Database.shape[0];dif=lag;Out=np.zeros([dimension-dif])\n",
    "    for i in range(dimension-dif):\n",
    "        Out[i]=(np.log(Database['Close'][i+dif])-np.log(Database['Close'][i]))\n",
    "    return np.append(np.repeat(np.nan, dif),Out), Database.index\n",
    "\n",
    "#STD Calculation\n",
    "def SDCalculation (DailyReturns, LagSD):\n",
    "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif])\n",
    "    for i in range (dimension-dif):\n",
    "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
    "    return np.append(np.repeat(np.nan, dif),Out)\n",
    "\n",
    "#STD Calculation\n",
    "def TrueSDCalculation (DailyReturns, LagSD):\n",
    "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif+1])\n",
    "    for i in range (dimension-dif+1):\n",
    "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
    "    return np.append(Out,np.repeat(np.nan, dif-1))\n",
    "\n",
    "\n",
    "#Database is calculated\n",
    "def DatabaseGeneration (Database, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database,Lag)\n",
    "    DailyReturnsOld =  np.append(np.repeat(np.nan, 1),DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
    "    SD = SDCalculation (DailyReturns, LagSD)\n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
    "    Data = pd.DataFrame({'DailyReturns': DailyReturns, 'SD': SD, 'TrueSD': TrueSD, 'DailyReturnsOld': DailyReturnsOld})\n",
    "    Data = Data.set_index(Index) \n",
    "    return Data.dropna()\n",
    "\n",
    "#Fitting of GARCH(1,1)\n",
    "def GARCH_Model_Student (Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    GARCH11 = arch_model(AR_Data, dist ='t')\n",
    "    res_GARCH11 = GARCH11.fit(disp='off')\n",
    "    CV_GARCH11 = res_GARCH11.conditional_volatility\n",
    "    For_CV_GARCH11 = np.array(res_GARCH11.forecast(horizon=4).variance.dropna())\n",
    "    return GARCH11, res_GARCH11, CV_GARCH11, For_CV_GARCH11\n",
    "\n",
    "#Fitting of GJR_GARCH(1,1)\n",
    "def GJR_GARCH_Model_Student (Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    GJR_GARCH11 = arch_model(AR_Data, p=1, o=1, q=1, dist ='t')\n",
    "    res_GJR_GARCH11 = GJR_GARCH11.fit(disp='off')\n",
    "    CV_GJR_GARCH11 = res_GJR_GARCH11.conditional_volatility\n",
    "    For_CV_GJR_GARCH11 = np.array(res_GJR_GARCH11.forecast(horizon=4).variance.dropna())\n",
    "    return GJR_GARCH11, res_GJR_GARCH11, CV_GJR_GARCH11, For_CV_GJR_GARCH11\n",
    "\n",
    "#Fitting of TARCH(1,1)\n",
    "def TARCH_Model_Student(Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    TARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist ='t')\n",
    "    res_TARCH11 = TARCH11.fit(disp='off')\n",
    "    CV_TARCH11 = res_TARCH11.conditional_volatility\n",
    "    For_CV_TARCH11 = np.array(res_TARCH11.forecast(horizon=4,method= \"bootstrap\").variance.dropna())\n",
    "    return TARCH11, res_TARCH11, CV_TARCH11, For_CV_TARCH11\n",
    "\n",
    "# #Fitting of EGARCH(1,1)\n",
    "# def EGARCH_Model_Student(Data):\n",
    "#     AR_Data=Data['DailyReturns']*100\n",
    "#     EGARCH11 = arch_model(AR_Data, dist ='t', vol=\"EGARCH\")\n",
    "#     res_EGARCH11 = EGARCH11.fit(disp='off')\n",
    "#     CV_EGARCH11 = res_EGARCH11.conditional_volatility\n",
    "#     For_CV_EGARCH11 = np.array(res_EGARCH11.forecast(horizon=4,method=\"bootstrap\").variance.dropna())\n",
    "#     return EGARCH11, res_EGARCH11,CV_EGARCH11, For_CV_EGARCH11\n",
    "\n",
    "#Fitting of TARCH(1,1)\n",
    "def EGARCH_Model_Student(Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    EGARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist ='t')\n",
    "    res_EGARCH11 = EGARCH11.fit(disp='off')\n",
    "    CV_EGARCH11 = res_EGARCH11.conditional_volatility\n",
    "    For_CV_EGARCH11 = np.array(res_EGARCH11.forecast(horizon=4,method= \"bootstrap\").variance.dropna())\n",
    "    return EGARCH11, res_EGARCH11,CV_EGARCH11, For_CV_EGARCH11\n",
    "\n",
    "#Fitting of Absolute Value GARCH(1,1)\n",
    "def AVGARCH_Model_Student(Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    AVGARCH11 = arch_model(AR_Data, dist ='t', power=1)\n",
    "    res_AVGARCH11 = AVGARCH11.fit(disp='off',options={'maxiter': 1000})\n",
    "    CV_AVGARCH11 = res_AVGARCH11.conditional_volatility\n",
    "    For_CV_AVGARCH11 = np.array(res_AVGARCH11.forecast(horizon=4,method=\"bootstrap\").variance.dropna())\n",
    "    return AVGARCH11, res_AVGARCH11, CV_AVGARCH11, For_CV_AVGARCH11\n",
    "\n",
    "#Fitting of FIGARCH11(1,1)\n",
    "def FIGARCH_Model_Student(Data):\n",
    "    AR_Data=Data['DailyReturns']*100\n",
    "    FIGARCH11 = arch_model(AR_Data, dist ='t', vol=\"FIGARCH\")\n",
    "    res_FIGARCH11 = FIGARCH11.fit(disp='off')\n",
    "    CV_FIGARCH11 = res_FIGARCH11.conditional_volatility\n",
    "    For_CV_FIGARCH11 = np.array(res_FIGARCH11.forecast(horizon=4,method=\"bootstrap\").variance.dropna())\n",
    "    return FIGARCH11, res_FIGARCH11, CV_FIGARCH11, For_CV_FIGARCH11\n",
    "\n",
    "#this old code was inconsistent with the original, it may be been forecasting steps y2,y3,y4,y5 instead of y1,y2,y3,y4\n",
    "# def Transformer_Database (Timestep, XData_AR, YData_AR):\n",
    "#     Features = XData_AR.shape[1]\n",
    "#     Sample = XData_AR.shape[0] - Timestep - 3  # Adjusted to allow for a 4-step-ahead target\n",
    "#     XDataTrainScaledRNN = np.zeros([Sample, Timestep, Features])\n",
    "#     YDataTrainRNN = np.zeros([Sample, 4])  # Adjusted for 4-step-ahead forecasts\n",
    "    \n",
    "#     for i in range(Sample):\n",
    "#         XDataTrainScaledRNN[i,:,:] = XData_AR[i:(Timestep+i)]\n",
    "#         YDataTrainRNN[i, :] = YData_AR[(Timestep+i):(Timestep+i+4)]  # 4-step-ahead target\n",
    "    \n",
    "#     return XDataTrainScaledRNN, YDataTrainRNN\n",
    "\n",
    "def Transformer_Database (Timestep, XData_AR, YData_AR):\n",
    "    Features = XData_AR.shape[1]\n",
    "    Sample = XData_AR.shape[0] - Timestep - 2  # Adjusted to allow for a 4-step-ahead target\n",
    "    XDataTrainScaledRNN = np.zeros([Sample, Timestep, Features])\n",
    "    YDataTrainRNN = np.zeros([Sample, 4])  # Adjusted for 4-step-ahead forecasts\n",
    "    \n",
    "    for i in range(Sample):\n",
    "        XDataTrainScaledRNN[i,:,:] = XData_AR[i:(Timestep+i)]\n",
    "        YDataTrainRNN[i, :] = YData_AR[(Timestep+i-1):(Timestep+i+3)]  # 4-step-ahead target\n",
    "    \n",
    "    return XDataTrainScaledRNN, YDataTrainRNN\n",
    "\n",
    "#MultiHeadSelfAttention\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.combine_heads = tf.keras.layers.Dense(embed_dim)\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(query, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(key, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(value, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(concat_attention)  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "        \n",
    "#Transformer Keras Block\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        # self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.nb_dict = {}; self.Bagging=5\n",
    "        for i in range(self.Bagging):\n",
    "          self.nb_dict[\"att{0}\".format(i)]=MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    def call(self, inputs, training):\n",
    "        self.att_dict = {}\n",
    "        for i in range(self.Bagging):\n",
    "          self.att_dict[\"att{0}\".format(i)]=self.nb_dict[\"att{0}\".format(i)](tf.keras.layers.Dropout(.1)(inputs))\n",
    "          if i==0: \n",
    "            self.att_dict[\"attn_output\"]=self.att_dict[\"att{0}\".format(i)]/self.Bagging \n",
    "          else: \n",
    "            self.att_dict[\"attn_output\"]=self.att_dict[\"attn_output\"]+self.att_dict[\"att{0}\".format(i)]/self.Bagging\n",
    "        attn_output = self.dropout1(self.att_dict[\"attn_output\"], training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "#Database is calculated\n",
    "def DatabaseGenerationForecast (Database, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database,Lag)\n",
    "    DailyReturnsOld =  np.append(np.repeat(np.nan, 1),DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
    "    SD = SDCalculation (DailyReturns, LagSD)\n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
    "    Data = pd.DataFrame({'DailyReturns': DailyReturns, 'SD': SD, 'TrueSD': TrueSD, 'DailyReturnsOld': DailyReturnsOld})\n",
    "    Data = Data.set_index(Index) \n",
    "    return Data\n",
    "\n",
    "#Database is calculated\n",
    "def M_DatabaseGenerationForecast (Database_daily, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database_daily,Lag)    \n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)    \n",
    "    Data = pd.DataFrame({'DailyReturns': DailyReturns,'TrueSD': TrueSD})\n",
    "    Data = Data.set_index(Index)\n",
    "    Data = Data.dropna() \n",
    "    weekly_returns = Data['DailyReturns'].resample('W-FRI').sum()\n",
    "    weekly_average_volatility = Data['TrueSD'].resample('W-FRI').mean()*np.sqrt(5)\n",
    "    \n",
    "    Data = pd.DataFrame({'DailyReturns': weekly_returns,'TrueSD': weekly_average_volatility})\n",
    "    return Data.dropna()\n",
    "\n",
    "def Transformer_Model (Shape1, Shape2, HeadsAttention,Dropout, LearningRate):\n",
    "    #Model struture is defined\n",
    "    Input = tf.keras.Input(shape=(Shape1,Shape2), name=\"Input\")\n",
    "    #LSTM is applied on top of the transformer\n",
    "    X = tf.keras.layers.LSTM(units=16, dropout=Dropout, return_sequences=True)(Input)\n",
    "    #Tranformer architecture is implemented\n",
    "    transformer_block_1 = TransformerBlock(embed_dim=16, num_heads=HeadsAttention, ff_dim=8, rate=Dropout)\n",
    "    X = transformer_block_1(X)\n",
    "    #Dense layers are used\n",
    "    X = tf.keras.layers.GlobalAveragePooling1D()(X)\n",
    "    X = tf.keras.layers.Dense(8, activation=tf.nn.sigmoid)(X)\n",
    "    X = tf.keras.layers.Dropout(Dropout)(X)\n",
    "    Output = tf.keras.layers.Dense(4, activation=tf.nn.sigmoid, name=\"Output\")(X)\n",
    "    model = tf.keras.Model(inputs=Input, outputs=Output)\n",
    "    #Optimizer is defined\n",
    "    Opt = tf.keras.optimizers.legacy.Adam(learning_rate=LearningRate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
    "    #Model is compiled\n",
    "    model.compile(optimizer=Opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def DatabaseGenerationForecast_AR (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH):\n",
    "    Data_Forecast=M_DatabaseGenerationForecast(Database, Lag, LagSD).iloc[(-2+1)]\n",
    "    Index_Forecast=M_DatabaseGenerationForecast(Database, Lag, LagSD).index[(-2+1)]\n",
    "    XDataForecast=[]\n",
    "    # Flatten the double-nested lists\n",
    "    For_CV_GARCH = [item for sublist in For_CV_GARCH for item in sublist]\n",
    "    For_CV_GJR_GARCH = [item for sublist in For_CV_GJR_GARCH for item in sublist]\n",
    "    For_CV_TARCH = [item for sublist in For_CV_TARCH for item in sublist]\n",
    "    For_CV_EGARCH = [item for sublist in For_CV_EGARCH for item in sublist]\n",
    "    For_CV_AVGARCH = [item for sublist in For_CV_AVGARCH for item in sublist]\n",
    "    For_CV_FIGARCH = [item for sublist in For_CV_FIGARCH for item in sublist]\n",
    "    for i in range(len(For_CV_AVGARCH)):\n",
    "        forecast={'CV_GARCH' : For_CV_GARCH[i]/100, 'CV_GJR_GARCH' : For_CV_GJR_GARCH[i]/100, 'CV_TARCH' : For_CV_TARCH[i]/100, \n",
    "               'CV_EGARCH' : For_CV_EGARCH[i]/100, 'CV_AVGARCH' : For_CV_AVGARCH[i]/100, 'CV_FIGARCH' : For_CV_FIGARCH[i]/100}\n",
    "        XDataForecast.append(pd.DataFrame([forecast], index=[Index_Forecast]))\n",
    "    XDataForecast = pd.concat(XDataForecast)\n",
    "    return XDataForecast, Data_Forecast['DailyReturns']\n",
    "\n",
    "def T_ANN_ARCH_Forecast (Database,Timestep, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH,Scaled_Norm, XData_AR, model):\n",
    "    XDataForecast, ReturnForecast = DatabaseGenerationForecast_AR (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH)\n",
    "    XDataForecast = pd.concat([XData_AR,XDataForecast])\n",
    "    XDataForecastTotalScaled = Scaled_Norm.transform(XDataForecast)\n",
    "    XDataForecastTotalScaled_T, Y_T = Transformer_Database(Timestep, XDataForecastTotalScaled, np.zeros(XDataForecastTotalScaled.shape[0]))\n",
    "    TransformerPrediction = model.predict(XDataForecastTotalScaled_T)\n",
    "    return TransformerPrediction[-2], XDataForecast.index[-1], TransformerPrediction[0:(XDataForecastTotalScaled_T.shape[0]-1)], ReturnForecast\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the data for the Transformer model:\n",
    "\n",
    "In the Transformer_Database function, you need to adjust the data preparation process to handle the 4-step-ahead forecast vectors from the ARCH models. This likely involves changes to how the X and Y arrays are constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DailyReturns</th>\n",
       "      <th>TrueSD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-12-16</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.008076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-23</th>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.010863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-30</th>\n",
       "      <td>-0.016187</td>\n",
       "      <td>0.019497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-06</th>\n",
       "      <td>0.029334</td>\n",
       "      <td>0.011155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-13</th>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.011531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-28</th>\n",
       "      <td>-0.004030</td>\n",
       "      <td>0.019568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-0.046276</td>\n",
       "      <td>0.031468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-11</th>\n",
       "      <td>-0.007545</td>\n",
       "      <td>0.034526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-18</th>\n",
       "      <td>-0.055645</td>\n",
       "      <td>0.036154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.032903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DailyReturns    TrueSD\n",
       "Date                              \n",
       "2005-12-16     -0.000087  0.008076\n",
       "2005-12-23      0.001057  0.010863\n",
       "2005-12-30     -0.016187  0.019497\n",
       "2006-01-06      0.029334  0.011155\n",
       "2006-01-13      0.001679  0.011531\n",
       "...                  ...       ...\n",
       "2007-12-28     -0.004030  0.019568\n",
       "2008-01-04     -0.046276  0.031468\n",
       "2008-01-11     -0.007545  0.034526\n",
       "2008-01-18     -0.055645  0.036154\n",
       "2008-01-25      0.004082  0.032903\n",
       "\n",
       "[111 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IndexEndDays=yf.download(asset,start=start,  end=end, progress=False).resample('W-FRI').last().index\n",
    "i = 4\n",
    "Database=yf.download(asset,start=IndexEndDays[i].date()-timedelta(days=780), end=IndexEndDays[i].date(), progress=False).resample('W-FRI').last()\n",
    "Database_daily = yf.download(asset,start=IndexEndDays[i].date()-timedelta(days=780), end=IndexEndDays[i].date()  , progress=False)\n",
    "#Database for fitting the models is generated\n",
    "LagSD=5\n",
    "Data = M_DatabaseGeneration(Database_daily, Lag, LagSD)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Lag=1; LagSD=5; Timestep=10; Dropout=0.05; LearningRate=0.01; Epochs = 100;BatchSize=64\n",
    "GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data)\n",
    "GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data)\n",
    "TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data)\n",
    "EGARCH, EGARCH_Parameters,CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data)\n",
    "AVGARCH, AVGARCH_Parameters,CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data)\n",
    "FIGARCH, FIGARCH_Parameters,CV_FIGARCH, For_CV_FIGARCH  = FIGARCH_Model_Student(Data)\n",
    "#Database contaning AR models is generated\n",
    "Data_AR=pd.concat([Data, CV_GARCH.rename('CV_GARCH')/100, CV_GJR_GARCH.rename('CV_GJR_GARCH')/100, CV_TARCH.rename('CV_TARCH')/100, \n",
    "                    CV_EGARCH.rename('CV_EGARCH')/100, CV_AVGARCH.rename('CV_AVGARCH')/100, CV_FIGARCH.rename('CV_FIGARCH')/100], axis=1)\n",
    "if Data_AR.shape[0]!=Data.shape[0]: print(\"Error in DB Generation\")\n",
    "# #Original explanatory and response variables are generated\n",
    "XData_AR = Data_AR.drop(['TrueSD','DailyReturns'], axis=1);YData_AR = Data_AR['TrueSD']\n",
    "# #Data is normalized\n",
    "Scaled_Norm = preprocessing.StandardScaler().fit(XData_AR); XData_AR_Norm = Scaled_Norm.transform(XData_AR)\n",
    "#Data for fitting the transformer model is generated\n",
    "XData_AR_Norm_T, YData_AR_Norm_T= Transformer_Database(Timestep, XData_AR_Norm, YData_AR)\n",
    "# #Model with transformer layer is defined\n",
    "model = Transformer_Model(XData_AR_Norm_T.shape[1], XData_AR_Norm_T.shape[2], HeadsAttention=4, Dropout=Dropout, LearningRate=LearningRate) #this shifts weekly True SD is working fine here\n",
    "model.fit(XData_AR_Norm_T, YData_AR_Norm_T, epochs=Epochs, verbose=0, batch_size=BatchSize); tf.keras.backend.clear_session()\n",
    "#T_ANN_ARCH_Forecast\n",
    "XDataForecast, ReturnForecast = DatabaseGenerationForecast_AR (Database_daily, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH)\n",
    "XDataForecast = pd.concat([XData_AR,XDataForecast*1/np.sqrt(5)])\n",
    "XDataForecastTotalScaled = Scaled_Norm.transform(XDataForecast)\n",
    "XDataForecastTotalScaled_T, Y_T = Transformer_Database(Timestep, XDataForecastTotalScaled, np.zeros(XDataForecastTotalScaled.shape[0]))\n",
    "TransformerPrediction = model.predict(XDataForecastTotalScaled_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01191176, 0.01445102, 0.01174104, 0.01137294],\n",
       "       [0.01445102, 0.01174104, 0.01137294, 0.0094715 ],\n",
       "       [0.01174104, 0.01137294, 0.0094715 , 0.01062454],\n",
       "       [0.01137294, 0.0094715 , 0.01062454, 0.01095153],\n",
       "       [0.0094715 , 0.01062454, 0.01095153, 0.01341099],\n",
       "       [0.01062454, 0.01095153, 0.01341099, 0.01595017],\n",
       "       [0.01095153, 0.01341099, 0.01595017, 0.01108245],\n",
       "       [0.01341099, 0.01595017, 0.01108245, 0.00899191],\n",
       "       [0.01595017, 0.01108245, 0.00899191, 0.0135342 ],\n",
       "       [0.01108245, 0.00899191, 0.0135342 , 0.01600366],\n",
       "       [0.00899191, 0.0135342 , 0.01600366, 0.01556924],\n",
       "       [0.0135342 , 0.01600366, 0.01556924, 0.02251559],\n",
       "       [0.01600366, 0.01556924, 0.02251559, 0.02504215],\n",
       "       [0.01556924, 0.02251559, 0.02504215, 0.01757864],\n",
       "       [0.02251559, 0.02504215, 0.01757864, 0.0256787 ],\n",
       "       [0.02504215, 0.01757864, 0.0256787 , 0.01695107],\n",
       "       [0.01757864, 0.0256787 , 0.01695107, 0.02283147],\n",
       "       [0.0256787 , 0.01695107, 0.02283147, 0.01448154],\n",
       "       [0.01695107, 0.02283147, 0.01448154, 0.01911007],\n",
       "       [0.02283147, 0.01448154, 0.01911007, 0.02498899],\n",
       "       [0.01448154, 0.01911007, 0.02498899, 0.015826  ],\n",
       "       [0.01911007, 0.02498899, 0.015826  , 0.00773225],\n",
       "       [0.02498899, 0.015826  , 0.00773225, 0.01272817],\n",
       "       [0.015826  , 0.00773225, 0.01272817, 0.01029569],\n",
       "       [0.00773225, 0.01272817, 0.01029569, 0.00666701],\n",
       "       [0.01272817, 0.01029569, 0.00666701, 0.01047901],\n",
       "       [0.01029569, 0.00666701, 0.01047901, 0.01303631],\n",
       "       [0.00666701, 0.01047901, 0.01303631, 0.00859178],\n",
       "       [0.01047901, 0.01303631, 0.00859178, 0.01242107],\n",
       "       [0.01303631, 0.00859178, 0.01242107, 0.01054882],\n",
       "       [0.00859178, 0.01242107, 0.01054882, 0.01094121],\n",
       "       [0.01242107, 0.01054882, 0.01094121, 0.00944638],\n",
       "       [0.01054882, 0.01094121, 0.00944638, 0.00586803],\n",
       "       [0.01094121, 0.00944638, 0.00586803, 0.01180431],\n",
       "       [0.00944638, 0.00586803, 0.01180431, 0.01269657],\n",
       "       [0.00586803, 0.01180431, 0.01269657, 0.00876534],\n",
       "       [0.01180431, 0.01269657, 0.00876534, 0.00414809],\n",
       "       [0.01269657, 0.00876534, 0.00414809, 0.01722052],\n",
       "       [0.00876534, 0.00414809, 0.01722052, 0.01289264],\n",
       "       [0.00414809, 0.01722052, 0.01289264, 0.0075495 ],\n",
       "       [0.01722052, 0.01289264, 0.0075495 , 0.00875079],\n",
       "       [0.01289264, 0.0075495 , 0.00875079, 0.0102334 ],\n",
       "       [0.0075495 , 0.00875079, 0.0102334 , 0.00866491],\n",
       "       [0.00875079, 0.0102334 , 0.00866491, 0.00836649],\n",
       "       [0.0102334 , 0.00866491, 0.00836649, 0.00689251],\n",
       "       [0.00866491, 0.00836649, 0.00689251, 0.01136925],\n",
       "       [0.00836649, 0.00689251, 0.01136925, 0.01509477],\n",
       "       [0.00689251, 0.01136925, 0.01509477, 0.00593567],\n",
       "       [0.01136925, 0.01509477, 0.00593567, 0.01136659],\n",
       "       [0.01509477, 0.00593567, 0.01136659, 0.00738665],\n",
       "       [0.00593567, 0.01136659, 0.00738665, 0.02768029],\n",
       "       [0.01136659, 0.00738665, 0.02768029, 0.02873228],\n",
       "       [0.00738665, 0.02768029, 0.02873228, 0.02210937],\n",
       "       [0.02768029, 0.02873228, 0.02210937, 0.02006647],\n",
       "       [0.02873228, 0.02210937, 0.02006647, 0.01443332],\n",
       "       [0.02210937, 0.02006647, 0.01443332, 0.01084376],\n",
       "       [0.02006647, 0.01443332, 0.01084376, 0.00872671],\n",
       "       [0.01443332, 0.01084376, 0.00872671, 0.01158928],\n",
       "       [0.01084376, 0.00872671, 0.01158928, 0.01182357],\n",
       "       [0.00872671, 0.01158928, 0.01182357, 0.01283003],\n",
       "       [0.01158928, 0.01182357, 0.01283003, 0.00868758],\n",
       "       [0.01182357, 0.01283003, 0.00868758, 0.01853711],\n",
       "       [0.01283003, 0.00868758, 0.01853711, 0.01026077],\n",
       "       [0.00868758, 0.01853711, 0.01026077, 0.01246966],\n",
       "       [0.01853711, 0.01026077, 0.01246966, 0.01219111],\n",
       "       [0.01026077, 0.01246966, 0.01219111, 0.02558571],\n",
       "       [0.01246966, 0.01219111, 0.02558571, 0.01852439],\n",
       "       [0.01219111, 0.02558571, 0.01852439, 0.01900804],\n",
       "       [0.02558571, 0.01852439, 0.01900804, 0.01187772],\n",
       "       [0.01852439, 0.01900804, 0.01187772, 0.01745666],\n",
       "       [0.01900804, 0.01187772, 0.01745666, 0.01962494],\n",
       "       [0.01187772, 0.01745666, 0.01962494, 0.02197789],\n",
       "       [0.01745666, 0.01962494, 0.02197789, 0.03151638],\n",
       "       [0.01962494, 0.02197789, 0.03151638, 0.04353781],\n",
       "       [0.02197789, 0.03151638, 0.04353781, 0.03439269],\n",
       "       [0.03151638, 0.04353781, 0.03439269, 0.03058251],\n",
       "       [0.04353781, 0.03439269, 0.03058251, 0.0291879 ],\n",
       "       [0.03439269, 0.03058251, 0.0291879 , 0.03186797],\n",
       "       [0.03058251, 0.0291879 , 0.03186797, 0.02585175],\n",
       "       [0.0291879 , 0.03186797, 0.02585175, 0.02444173],\n",
       "       [0.03186797, 0.02585175, 0.02444173, 0.01974086],\n",
       "       [0.02585175, 0.02444173, 0.01974086, 0.01389912],\n",
       "       [0.02444173, 0.01974086, 0.01389912, 0.01416654],\n",
       "       [0.01974086, 0.01389912, 0.01416654, 0.01291287],\n",
       "       [0.01389912, 0.01416654, 0.01291287, 0.02828291],\n",
       "       [0.01416654, 0.01291287, 0.02828291, 0.02070851],\n",
       "       [0.01291287, 0.02828291, 0.02070851, 0.03496968],\n",
       "       [0.02828291, 0.02070851, 0.03496968, 0.03942931],\n",
       "       [0.02070851, 0.03496968, 0.03942931, 0.03231433],\n",
       "       [0.03496968, 0.03942931, 0.03231433, 0.04338825],\n",
       "       [0.03942931, 0.03231433, 0.04338825, 0.02980599],\n",
       "       [0.03231433, 0.04338825, 0.02980599, 0.02981855],\n",
       "       [0.04338825, 0.02980599, 0.02981855, 0.02568432],\n",
       "       [0.02980599, 0.02981855, 0.02568432, 0.02141241],\n",
       "       [0.02981855, 0.02568432, 0.02141241, 0.01956824],\n",
       "       [0.02568432, 0.02141241, 0.01956824, 0.03146848],\n",
       "       [0.02141241, 0.01956824, 0.03146848, 0.03452627],\n",
       "       [0.01956824, 0.03146848, 0.03452627, 0.0361538 ],\n",
       "       [0.03146848, 0.03452627, 0.0361538 , 0.03290269]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YData_AR_Norm_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XData_AR_Norm_T.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_GARCH</th>\n",
       "      <th>CV_GJR_GARCH</th>\n",
       "      <th>CV_TARCH</th>\n",
       "      <th>CV_EGARCH</th>\n",
       "      <th>CV_AVGARCH</th>\n",
       "      <th>CV_FIGARCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-12-21</th>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>0.020952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-28</th>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>0.021529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-11</th>\n",
       "      <td>0.020682</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>0.019174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-18</th>\n",
       "      <td>0.020733</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.024470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.023615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.035062</td>\n",
       "      <td>0.023739</td>\n",
       "      <td>0.023739</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.038863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.019502</td>\n",
       "      <td>0.035167</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.023969</td>\n",
       "      <td>0.034621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.033160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-25</th>\n",
       "      <td>0.019692</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.032037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CV_GARCH  CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  \\\n",
       "2007-12-21  0.020527      0.023035  0.022328   0.022328    0.022328   \n",
       "2007-12-28  0.020579      0.022727  0.022440   0.022440    0.022440   \n",
       "2008-01-04  0.020630      0.022468  0.022552   0.022552    0.022552   \n",
       "2008-01-11  0.020682      0.025162  0.022664   0.022664    0.022664   \n",
       "2008-01-18  0.020733      0.024920  0.022776   0.022776    0.022776   \n",
       "2008-01-25  0.020785      0.028402  0.022888   0.022888    0.022888   \n",
       "2008-01-25  0.019406      0.035062  0.023739   0.023739    0.023738   \n",
       "2008-01-25  0.019502      0.035167  0.023970   0.023970    0.023969   \n",
       "2008-01-25  0.019597      0.035272  0.024203   0.024203    0.024202   \n",
       "2008-01-25  0.019692      0.035377  0.024437   0.024437    0.024435   \n",
       "\n",
       "            CV_FIGARCH  \n",
       "2007-12-21    0.020952  \n",
       "2007-12-28    0.021529  \n",
       "2008-01-04    0.020496  \n",
       "2008-01-11    0.019174  \n",
       "2008-01-18    0.024470  \n",
       "2008-01-25    0.023615  \n",
       "2008-01-25    0.038863  \n",
       "2008-01-25    0.034621  \n",
       "2008-01-25    0.033160  \n",
       "2008-01-25    0.032037  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XDataForecast.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03037949, 0.03800619, 0.02900026, 0.03645329], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformerPrediction[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_ANN_ARCH_Fit (Data,Database,Lag=1, LagSD=5, Timestep=10, Dropout=0.05, LearningRate=0.01, Epochs=1000, BatchSize=64):\n",
    "    GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data)\n",
    "    GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data)\n",
    "    TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data)\n",
    "    EGARCH, EGARCH_Parameters,CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data)\n",
    "    AVGARCH, AVGARCH_Parameters,CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data)\n",
    "    FIGARCH, FIGARCH_Parameters,CV_FIGARCH, For_CV_FIGARCH  = FIGARCH_Model_Student(Data)\n",
    "    #Database contaning AR models is generated\n",
    "    Data_AR=pd.concat([Data, CV_GARCH.rename('CV_GARCH')/100, CV_GJR_GARCH.rename('CV_GJR_GARCH')/100, CV_TARCH.rename('CV_TARCH')/100, \n",
    "                        CV_EGARCH.rename('CV_EGARCH')/100, CV_AVGARCH.rename('CV_AVGARCH')/100, CV_FIGARCH.rename('CV_FIGARCH')/100], axis=1)\n",
    "    if Data_AR.shape[0]!=Data.shape[0]: print(\"Error in DB Generation\")\n",
    "    # #Original explanatory and response variables are generated\n",
    "    XData_AR = Data_AR.drop(['TrueSD','DailyReturns'], axis=1);YData_AR = Data_AR['TrueSD']\n",
    "    # #Data is normalized\n",
    "    Scaled_Norm = preprocessing.StandardScaler().fit(XData_AR); XData_AR_Norm = Scaled_Norm.transform(XData_AR)\n",
    "    #Data for fitting the transformer model is generated\n",
    "    XData_AR_Norm_T, YData_AR_Norm_T= Transformer_Database(Timestep, XData_AR_Norm, YData_AR)\n",
    "    #Model with transformer layer is defined\n",
    "    model = Transformer_Model(XData_AR_Norm_T.shape[1], XData_AR_Norm_T.shape[2], HeadsAttention=4, Dropout=Dropout, LearningRate=LearningRate)\n",
    "    model.fit(XData_AR_Norm_T, YData_AR_Norm_T, epochs=Epochs, verbose=0, batch_size=BatchSize); tf.keras.backend.clear_session()\n",
    "    Forecast, Date_Forecast, TrainPrediction, ReturnForecast = T_ANN_ARCH_Forecast (Database,Timestep, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH,Scaled_Norm, XData_AR, model)\n",
    "    return {'Date_Forecast':Date_Forecast,'Forecast_T_ANN_ARCH':Forecast }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout  = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/418 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/418 [00:07<50:02,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/418 [00:13<45:34,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/418 [00:19<44:18,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/418 [00:26<45:20,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/418 [00:32<44:13,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/418 [00:38<43:39,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/418 [00:44<42:42,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/418 [00:50<40:47,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/418 [00:55<39:34,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/418 [01:01<38:55,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/418 [01:07<39:28,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/418 [01:12<38:49,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/418 [01:18<39:32,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/418 [01:25<41:11,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 15/418 [01:31<41:07,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/418 [01:37<41:00,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/418 [01:43<40:55,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/418 [01:50<42:23,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 19/418 [01:58<44:23,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 20/418 [02:04<43:22,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 21/418 [02:11<43:26,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 22/418 [02:17<42:31,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 23/418 [02:24<44:32,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 24/418 [02:31<44:13,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 25/418 [02:36<41:30,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 26/418 [02:42<39:21,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 27/418 [02:47<38:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 28/418 [02:53<38:16,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 29/418 [02:58<37:15,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 30/418 [03:04<36:27,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 31/418 [03:09<35:55,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 32/418 [03:15<36:51,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 33/418 [03:21<36:35,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 34/418 [03:28<38:15,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 35/418 [03:34<39:10,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 36/418 [03:40<37:44,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 37/418 [03:45<36:42,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 38/418 [03:51<36:55,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 39/418 [03:56<36:10,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 40/418 [04:02<36:28,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 41/418 [04:08<35:56,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 42/418 [04:15<38:50,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 43/418 [04:21<38:08,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 44/418 [04:27<37:49,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 45/418 [04:33<37:13,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 46/418 [04:39<37:54,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 47/418 [04:45<36:57,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 48/418 [04:50<35:50,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 49/418 [04:56<35:53,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 50/418 [05:02<34:55,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 51/418 [05:07<34:26,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 52/418 [05:13<34:59,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 53/418 [05:19<34:14,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 54/418 [05:24<33:48,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 55/418 [05:30<34:36,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 56/418 [05:37<36:16,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 57/418 [05:43<36:18,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 58/418 [05:50<37:48,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 59/418 [05:56<37:17,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 60/418 [06:02<37:52,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 61/418 [06:09<37:32,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 62/418 [06:14<35:56,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 63/418 [06:20<35:48,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 64/418 [06:26<34:41,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 65/418 [06:31<33:48,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 66/418 [06:36<33:02,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 67/418 [06:42<33:40,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 68/418 [06:48<33:03,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 69/418 [06:53<32:38,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 70/418 [06:59<33:14,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 71/418 [07:05<32:36,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 72/418 [07:10<32:06,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 73/418 [07:16<32:45,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 74/418 [07:22<32:10,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 75/418 [07:27<32:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 76/418 [07:33<31:36,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 77/418 [07:39<32:20,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 78/418 [07:44<31:48,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 79/418 [07:50<31:26,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 80/418 [07:55<31:11,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 81/418 [08:01<32:00,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 82/418 [08:07<32:35,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 83/418 [08:13<33:06,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 84/418 [08:20<34:23,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 85/418 [08:26<34:19,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 86/418 [08:32<34:03,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 87/418 [08:40<35:44,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 88/418 [08:46<36:01,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 89/418 [08:53<35:14,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 90/418 [09:00<36:15,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 91/418 [09:07<36:36,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 92/418 [09:13<35:38,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 93/418 [09:20<36:33,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 94/418 [09:30<41:43,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 95/418 [09:36<38:57,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 96/418 [09:42<37:15,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 97/418 [09:48<35:42,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 98/418 [09:55<36:02,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 99/418 [10:02<36:24,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 100/418 [10:08<35:05,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 101/418 [10:15<34:09,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 102/418 [10:21<32:06,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- BA: No data found for this date range, symbol may be delisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m#Loop for generating the results\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(IndexEndDays\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])):\n\u001b[1;32m     14\u001b[0m     \u001b[39m#Database is downloaded from yahoo finance and lag of returns defined\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     Database\u001b[39m=\u001b[39myf\u001b[39m.\u001b[39;49mdownload(asset,start\u001b[39m=\u001b[39;49mIndexEndDays[i]\u001b[39m.\u001b[39;49mdate()\u001b[39m-\u001b[39;49mtimedelta(days\u001b[39m=\u001b[39;49m\u001b[39m780\u001b[39;49m), end\u001b[39m=\u001b[39;49mIndexEndDays[i]\u001b[39m.\u001b[39;49mdate(), progress\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39;49mresample(\u001b[39m'\u001b[39;49m\u001b[39mW-FRI\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mlast()\n\u001b[1;32m     16\u001b[0m     Database_daily \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39mdownload(asset,start\u001b[39m=\u001b[39mIndexEndDays[i]\u001b[39m.\u001b[39mdate()\u001b[39m-\u001b[39mtimedelta(days\u001b[39m=\u001b[39m\u001b[39m780\u001b[39m), end\u001b[39m=\u001b[39mIndexEndDays[i]\u001b[39m.\u001b[39mdate()  , progress\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m     \u001b[39m#Database for fitting the models is generated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis_2/lib/python3.10/site-packages/pandas/core/generic.py:8083\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset)\u001b[0m\n\u001b[1;32m   8080\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresample\u001b[39;00m \u001b[39mimport\u001b[39;00m get_resampler\n\u001b[1;32m   8082\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8083\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[1;32m   8084\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8085\u001b[0m     freq\u001b[39m=\u001b[39;49mrule,\n\u001b[1;32m   8086\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   8087\u001b[0m     closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[1;32m   8088\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8089\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m   8090\u001b[0m     loffset\u001b[39m=\u001b[39;49mloffset,\n\u001b[1;32m   8091\u001b[0m     convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[1;32m   8092\u001b[0m     base\u001b[39m=\u001b[39;49mbase,\n\u001b[1;32m   8093\u001b[0m     key\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   8094\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8095\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m   8096\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   8097\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis_2/lib/python3.10/site-packages/pandas/core/resample.py:1270\u001b[0m, in \u001b[0;36mget_resampler\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1270\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39;49m_get_resampler(obj, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/thesis_2/lib/python3.10/site-packages/pandas/core/resample.py:1435\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[1;32m   1433\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(obj, groupby\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis)\n\u001b[0;32m-> 1435\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1436\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1437\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1438\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1439\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "#Index of end dates, database for validation and dataframe to collect the results are created. Model variables are defined.\n",
    "Start='2008-01-01'; End='2015-12-31'; \n",
    "asset = \"BA\"\n",
    "# asset_name = re.sub('[\\W\\d_]+', '', asset)\n",
    "IndexEndDays=yf.download(asset,start=Start,  end=End, progress=False).resample('W-FRI').last().index\n",
    "\n",
    "Lag=1; LagSD=5; Timestep=10; Dropout=0.1; LearningRate=0.01; Epochs=100\n",
    "\n",
    "DataValidation = DatabaseGeneration(yf.download(asset,start='2000-01-01', end=date.today()+timedelta(days=1), progress=False).resample('W-FRI').last(), Lag, LagSD)\n",
    "\n",
    "ResultsCollection=pd.DataFrame({'Date_Forecast': [], 'h1': [], 'h2': [], 'h3':[], 'h4': [],'TrueSD':[]})\n",
    "#Loop for generating the results\n",
    "for i in tqdm(range(IndexEndDays.shape[0])):\n",
    "    #Database is downloaded from yahoo finance and lag of returns defined\n",
    "    Database=yf.download(asset,start=IndexEndDays[i].date()-timedelta(days=780), end=IndexEndDays[i].date(), progress=False).resample('W-FRI').last()\n",
    "    Database_daily = yf.download(asset,start=IndexEndDays[i].date()-timedelta(days=780), end=IndexEndDays[i].date()  , progress=False)\n",
    "\n",
    "    #Database for fitting the models is generated\n",
    "    Data = M_DatabaseGeneration(Database_daily, Lag, LagSD)\n",
    "    #Fitting of Transformed ANN-ARCH model, ARCH models and forecasting of the next volatility value\n",
    "    T_ANN_ARCH_Model = T_ANN_ARCH_Fit (Data,Database_daily, Lag, LagSD, Timestep, Dropout, LearningRate, Epochs)\n",
    "\n",
    "    \n",
    "    IterResults={'Date_Forecast': T_ANN_ARCH_Model['Date_Forecast'].date(), 'h1': T_ANN_ARCH_Model['Forecast_T_ANN_ARCH'][0], 'h2': T_ANN_ARCH_Model['Forecast_T_ANN_ARCH'][1],\n",
    "                 'h3': T_ANN_ARCH_Model['Forecast_T_ANN_ARCH'][2], 'h4': T_ANN_ARCH_Model['Forecast_T_ANN_ARCH'][3],'TrueSD':Data['TrueSD'][-1]}\n",
    "    \n",
    "    IterResults_df = pd.DataFrame(IterResults,index =[0])\n",
    "    ResultsCollection = ResultsCollection.append(IterResults_df, ignore_index=True)\n",
    "\n",
    "    # ResultsCollection.to_csv(f'./assets/5_MTL_GARCH_{asset_name}.csv',index=False)\n",
    "    ResultsCollection.to_csv(f'./BA.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
